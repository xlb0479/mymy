# 日志架构

应用和系统日志可以让你知道集群里正在发生的事儿。日志对于调试和监控集群活动都是非常有用的。现在大部分的应用都有一定的日志机制；因此，大部分的容器引擎也设计了某种程度的日志支持。对于容器化应用来说，最简单同时也是接受程度最高的日志记录方法就是把日志打到标准输出和标准错误流上。

但是容器引擎或运行时提供的原生功能并不足以形成一个完整的日志解决方案。比如，如果容器崩了，Pod被踢掉了，或者节点完犊子了，但是你可能仍然希望能看到应用的日志。所以日志的存储和声明周期应当是独立于节点、Pod或容器。我们把这个概念叫做*集群日志（cluster-level-logging）*。集群日志需要单独的后端来存储、分析和查询日志。k8s并没有提供原生的日志数据存储方案，但是你可以集成很多已有的日志方案到集群中来。

我们这里讲集群日志架构的时候，首先会假设已经有一个日志后端服务部署在你的集群中或者集群外部了。如果你对集群日志没兴趣，在这里仍然会了解到日志是如何在节点本地存储和处理的，也是蛮有用的知识点。

## k8s的日志

在这一节中，呢会看到一个关于k8s日志的基本的栗子，它把数据输出到了标准输出流上。这个栗子用了一份[Pod定义](https://v1-18.docs.kubernetes.io/examples/debug/counter-pod.yaml)，里面包含了一个容器，每秒钟向标准输出写入一些文本。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args: [/bin/sh, -c,
            'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']
```

运行下面的命令把这个Pod跑起来：

```shell script
kubectl apply -f https://k8s.io/examples/debug/counter-pod.yaml
```

输出如下：

```text
pod/counter created
```

要想看日志，用`kubectl logs`命令：

```shell script
kubectl logs counter
```

输出：

```text
0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
```

可以在`kubectl logs`命名上加上`--previous`选项，可以看到之前容器实例的日志，以防容器挂掉。如果Pod中包含了多个容器，那就把你想看的容器名字加到命令后面。详见[`kubectl logs`文档](https://v1-18.docs.kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs)。

## 节点上的日志

![logging-node-level.png](img/logging-node-level.png)

每个容器应用写到`stdout`和`stderr`的数据都被容器引擎处理并重定向到其他地方。比如Docker就会把这两个流重定向到[一个日志驱动](https://docs.docker.com/config/containers/logging/configure/)，k8s把它配置成按照JSON格式写入到一个文件中。

>**注意**：Docker的json日志驱动会把每一行作为一条单独的消息。当你用Docker日志驱动的时候，没有直接支持多行消息的方法。你需要在日志代理层或者更高的层次上处理多行消息。

默认情况下，如果容器重启，kubelet会保留一个结束的容器跟它的日志。如果Pod从这个节点上被踢掉了，所有对应的容器都会被踢掉，连同它们的日志。

在节点级别的日志管理中，一个很重要的事儿就是日志的滚动（rotation），这样日志才不会把所有的存储空间都吃掉。k8s目前是不管日志滚动的事儿的，但是部署工具应当有这方面的功能。比如用`kube-up.sh`部署的k8s集群，会有一个[`logrotate`](https://linux.die.net/man/8/logrotate)工具，每小时运行一次。或者你也可以配置一下容器运行时，让它来自动滚动应用的日志，比如用Docker的`log-opt`。在`kube-up.sh`脚本中，后者用于GCP上的COS镜像，前者用于其他环境。不论是哪种情况，当日志文件超过10MB的时候默认都会发生日志滚动。

在对应的[脚本](https://github.com/kubernetes/kubernetes/blob/v1.18.8/cluster/gce/gci/configure-helper.sh)中你可以找到关于`kube-up.sh`如何为GCP上的COS镜像部署日志记录功能的详细信息。

当你在上面的栗子中使用[`kubectl logs`](https://v1-18.docs.kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs)的时候，节点上的kubelet会处理相应的请求，直接读取日志文件，把内容返回来。

>**注意**：目前来说，如果有外部系统做了日志的滚动，那么在`kubectl logs`命令中就只能看到最后一个日志文件的内容。比如出现了一个10MB的文件，`logrotate`做了滚动，然后出现了两个文件，一个10MB一个空的，此时执行`kubectl logs`就什么也看不到。

### 系统组件日志

有两类系统组件：运行在容器中的，以及不运行在容器中的。比如：

- k8s调度器和kube-proxy是运行在容器中的。
- kubelet和容器运行时，比如Docker，不是运行在容器中的。

如果主机有systemd，kubelet和容器运行时会把日志写到journald。如果没有systemd，则会写到`/var/log`目录的`.log`文件中。容器中运行的系统组件总是会写到`/var/log`目录中，绕过了默认的日志机制。它们用的是[klog](https://github.com/kubernetes/klog)日志库。可以在[日志开发文档](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md)中找到这些组件记录日志时关于日志级别的约定。

和容器日志类似，`/var/log`目录中的系统组件的日志也需要滚动。如果是用`kube-up.sh`脚本部署的k8s集群，这些日志会被`logrotate`工具进行每天一次的滚动处理，或者是文件大小超过100MB的时候。

## 集群日志架构

虽然k8s没有提供原生的集群日志方案，但是有很多常用的方法你都可以考虑采纳。这里给出几种方法：

- 每个节点运行一个节点级别的日志代理。
- 在应用Pod中包含一个sidecar容器来做日志记录。
- 在应用中直接把日志推到日志服务上。

### 使用节点日志代理

![logging-with-node-agent.png](img/logging-with-node-agent.png)

可以在每个节点上引入一个*节点级别的代理*来实现集群日志。日志代理是一个专用工具，负责暴露或将日志推到日志服务上。一般来说，节点代理也是运行在容器中，并且能够访问所在节点的所有应用容器的日志目录。

因为日志代理必须要运行在每个节点上，所以经常实现成一个DaemonSet副本，或者是专用的Pod，再或者是节点本地的普通进程。但是后两种方法都废弃了，非常不建议用。

使用节点级别的日志代理在k8s中时最为常用和推荐使用的方法，因为它只会在每个节点创建一个代理，不需要对节点上的应用Pod做任何的修改。但是，这个但是很重要，节点级别的日志*只能处理应用的标准输出和标准错误*。

k8s本身不会定义日志代理，但是k8s中打包了两个可选的日志代理：[Stackdriver](https://v1-18.docs.kubernetes.io/docs/tasks/debug-application-cluster/logging-stackdriver/)，用于GCP，以及[Elasticsearch](https://v1-18.docs.kubernetes.io/docs/tasks/debug-application-cluster/logging-elasticsearch-kibana/)。可以在它们各自的文档中查看更多细节。它们都是用[fluentd](https://www.fluentd.org/)加一些自定义的配置来做节点代理。

### sidecar模式的日志代理

可以通过以下两种方式之一实现sidecar容器：

- sidecar容器将应用日志流转到自己的`stdout`上。
- sidecar容器里运行一个日志代理，抓取应用容器中的日志。

#### 日志流模式

![logging-with-streaming-sidecar.png](img/logging-with-streaming-sidecar.png)

当sidecar容器将日志流转移到自身的`stdout`和`stderr`上之后，就可以利用节点上已经有的kubelet和日志代理了。sidecar容器可以从文件、socket或journald中读取日志。每个sidecar容器将日志输出到自身的`stdout`或`stderr`流上。

这种方法可以将应用中各部分的日志分发到多个日志流上，其中某些部分可能原本很难支持写到`stdout`或`stderr`上。日志的重定向逻辑很简单，几乎形不成什么压力。而且，因为`stdout`和`stderr`是由kubelet处理的，所以你还可以用`kubectl logs`命令。

来看下面的栗子。Pod中只运行了一个容器，生成两个日志文件，格式也不同：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args:
    - /bin/sh
    - -c
    - >
      i=0;
      while true;
      do
        echo "$i: $(date)" >> /var/log/1.log;
        echo "$(date) INFO $i" >> /var/log/2.log;
        i=$((i+1));
        sleep 1;
      done
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  volumes:
  - name: varlog
    emptyDir: {}
```

如果把两个不同格式的日志打到同一个日志流上，那就祸祸成一锅粥了，即便都整合到`stdout`也是如此。这种情况下，你可以引入两个sidecar容器。基于共享数据卷，每个sidecar容器可以单独处理一个日志文件，并将日志流重定向到自身的`stdout`上。

下面就是一个Pod带两个sidecar：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args:
    - /bin/sh
    - -c
    - >
      i=0;
      while true;
      do
        echo "$i: $(date)" >> /var/log/1.log;
        echo "$(date) INFO $i" >> /var/log/2.log;
        i=$((i+1));
        sleep 1;
      done
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  - name: count-log-1
    image: busybox
    args: [/bin/sh, -c, 'tail -n+1 -f /var/log/1.log']
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  - name: count-log-2
    image: busybox
    args: [/bin/sh, -c, 'tail -n+1 -f /var/log/2.log']
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  volumes:
  - name: varlog
    emptyDir: {}
```

现在当你运行Pod的时候，可以分别访问不同的日志流：

```shell script
kubectl logs counter count-log-1
```

```text
0: Mon Jan  1 00:00:00 UTC 2001
1: Mon Jan  1 00:00:01 UTC 2001
2: Mon Jan  1 00:00:02 UTC 2001
...
```

```shell script
kubectl logs counter count-log-2
```

```text
Mon Jan  1 00:00:00 UTC 2001 INFO 0
Mon Jan  1 00:00:01 UTC 2001 INFO 1
Mon Jan  1 00:00:02 UTC 2001 INFO 2
...
```

此时，集群中已经安装好的节点日志代理会自动抓取这些日志流，不需要再加任何配置。而且，你还可以配置让代理按照数据源容器的不同，使用不同的日志解析方式。

但是要注意，虽然这里对CPU和内存的消耗不高（若干millcore的CPU以及若干MB的内存），但是把日志写到文件，再从文件中流转到`stdout`会导致双倍的磁盘占用。如果你的应用只会将日志输出到一个单独的文件中，那最好是直接输出到`/dev/stdout`，而不是用这种sidecar容器来流转。

如果应用自身做不了日志滚动，还可以用sidecar容器来做。比如用一个小容器定期运行logrotate。但是吧，最好还是直接输出到`stdout`和`stderr`，把日志滚动这种事儿交给kubelet。

#### 日志代理模式的sidecar

![logging-with-sidecar-agent.png](img/logging-with-sidecar-agent.png)

如果节点日志代理对于你的场景仍然不够灵活，那就可以用sidecar容器，里面再加一个单独的日志代理，单独处理应用的日志。

>**注意**：在sidecar容器中运行日志代理可能会导致严重的资源消耗。而且你无法用`kubectl logs`命令来访问这些日志，因为它们不受kubelet控制。

比如，你可以用[Stackdriver](https://v1-18.docs.kubernetes.io/docs/tasks/debug-application-cluster/logging-stackdriver/)，它内部是用了fluentd做了日志代理。这里给出了两个配置文件可以用来实现这个机制。第一个文件是配置fluentd的[ConfigMap](https://v1-18.docs.kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/)。

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
data:
  fluentd.conf: |
    <source>
      type tail
      format none
      path /var/log/1.log
      pos_file /var/log/1.log.pos
      tag count.format1
    </source>

    <source>
      type tail
      format none
      path /var/log/2.log
      pos_file /var/log/2.log.pos
      tag count.format2
    </source>

    <match **>
      type google_cloud
    </match>
```

>**注意**：fluentd的配置远不止于此。关于如何配置fluentd，参见[官方文档](https://docs.fluentd.org/)。

第二个文件定义了Pod，包含了一个运行fluentd的sidecar容器。Pod挂载了一个数据卷，fluentd可以从中读取它的配置数据。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args:
    - /bin/sh
    - -c
    - >
      i=0;
      while true;
      do
        echo "$i: $(date)" >> /var/log/1.log;
        echo "$(date) INFO $i" >> /var/log/2.log;
        i=$((i+1));
        sleep 1;
      done
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  - name: count-agent
    image: k8s.gcr.io/fluentd-gcp:1.30
    env:
    - name: FLUENTD_ARGS
      value: -c /etc/fluentd-config/fluentd.conf
    volumeMounts:
    - name: varlog
      mountPath: /var/log
    - name: config-volume
      mountPath: /etc/fluentd-config
  volumes:
  - name: varlog
    emptyDir: {}
  - name: config-volume
    configMap:
      name: fluentd-config
```

稍等一会儿你就能通过Stackdriver的接口看到这些日志消息了。

### 应用直接转移日志

![logging-from-application.png](img/logging-from-application.png)

可以让每个应用直接暴露或进行日志推送来实现集群日志；但是这种方式已经超出了k8s的知识范围。